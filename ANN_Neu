#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Feb  3 19:54:28 2022

@author: muqiliu
"""

import numpy as np
import pandas as pd
#import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from keras import regularizers
from keras.layers import Dropout

import matplotlib.pyplot as plt


#Call data(csvv-file)
dataset = pd.read_csv("/Users/muqiliu/Desktop/CT.csv", header = None)#, verbose=False, sep=";"
dataset = dataset.drop(0)

X = dataset.iloc[:,1:6] #unabhängige Variable
y = dataset.iloc[:,6:7] #abhängige Variable

X=np.asarray(X).astype(np.float32)
y=np.asarray(y).astype(np.float32)



#Normalizing the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
##X_test = sc.transform(X_test)

from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder()
y = ohe.fit_transform(y).toarray()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)
############################## Initiate model 1 ###############################
# Model 1 has no hidden layers
model1 = keras.Sequential()
model1.add(layers.Dense(16, activation = "sigmoid"))
#model1.add(layers.Dense(16, activation = "tanh"))
#model1.add(layers.Dense(8, activation = "sigmoid"))
model1.add(Dropout(0.2))

#output layer with 1 output
model1.add(layers.Dense(1, activation = "linear"))

# Compile the model
model1.compile(loss="mean_squared_error", optimizer='adam') #, metrics= ['accuracy']


# Fit model
history1 = model1.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size = 64)#


############################## Initiate model 2 ###############################
# Model 2 has 1 hidden layer 

model2 = keras.Sequential()
#input layer
model2.add(layers.Dense(16, activation = "sigmoid" ,kernel_regularizer=regularizers.l2(0.001)))
#model2.add(layers.Dense(16, activation = "tanh"))
#model2.add(layers.Dense(8, activation = "sigmoid"))
model2.add(Dropout(0.2))

#add 1 hidden layer
model2.add(layers.Dense(16, activation = "sigmoid", kernel_regularizer=regularizers.l2(0.001)))
model2.add(Dropout(0.2))

#output layer with 1 output
model2.add(layers.Dense(1, activation = "linear"))


# Compile the model
model2.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy']) 
#history2 = model2.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=100, batch_size = 64)
history2 = model2.fit(X_train, y_train, epochs=100, batch_size = 64)

############################## model3
model3 = keras.Sequential()
#input layer
model3.add(layers.Dense(16, activation = "sigmoid" ,kernel_regularizer=regularizers.l2(0.001)))
#model2.add(layers.Dense(16, activation = "tanh"))
#model2.add(layers.Dense(8, activation = "sigmoid"))
model3.add(Dropout(0.2))

#add 1 hidden layer
model3.add(layers.Dense(16, activation = "sigmoid", kernel_regularizer=regularizers.l2(0.001)))
model3.add(Dropout(0.2))

#output layer with 1 output
model3.add(layers.Dense(1, activation = "linear"))


# Compile the model
model3.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy']) 
history3 = model3.fit(X_test, y_test,  epochs=100, batch_size = 64)






# check the model’s performance on test data
y_pred = model2.predict(X_test)
#Converting predictions to label
pred = list()
for i in range(len(y_pred)):
    pred.append(np.argmax(y_pred[i]))
#Converting one hot encoded test label to label
test = list()
for i in range(len(y_test)):
    test.append(np.argmax(y_test[i]))

#We will get integer labels using this step    
from sklearn.metrics import accuracy_score
a = accuracy_score(pred,test)
print('Accuracy is:', a*100)

# Fit model

# Plot the models
#plt.plot(history1.history['val_loss'],'r', history2.history['val_loss'], 'b' )
plt.plot(history1.history['loss'],'r', history2.history['loss'], 'b' )
plt.xlabel('Epochs')
plt.ylabel('Validation score')
plt.show()

# Plot the models

plt.plot(history2.history['accuracy'])
plt.plot(history3.history['accuracy'])
#lt.plot(history2.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history2.history['loss']) 
plt.plot(history3.history['loss']) 
#plt.plot(history2.history['val_loss']) 
plt.title('Model loss') 
plt.ylabel('Loss') 
plt.xlabel('Epoch') 
plt.legend(['Train', 'Test'], loc='upper left') 
plt.show()
